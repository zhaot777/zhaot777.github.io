<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Steven&#39;s Blog</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://zhaot777.github.io/"/>
  <updated>2016-06-19T23:53:23.145Z</updated>
  <id>http://zhaot777.github.io/</id>
  
  <author>
    <name>Steven Zhao</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Big Data Review</title>
    <link href="http://zhaot777.github.io/2016/06/19/DB_BigData/"/>
    <id>http://zhaot777.github.io/2016/06/19/DB_BigData/</id>
    <published>2016-06-19T23:37:11.872Z</published>
    <updated>2016-06-19T23:53:23.145Z</updated>
    
    <content type="html">&lt;h3 id=&quot;What-is-Big-Data&quot;&gt;&lt;a href=&quot;#What-is-Big-Data&quot; class=&quot;headerlink&quot; title=&quot;What is Big Data&quot;&gt;&lt;/a&gt;What is Big Data&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Big Data is data that is ‘too big’ to be stored in a single machine, and/or processed by a single machine.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Feature: Variety, Velocity, Volume&lt;ul&gt;
&lt;li&gt;Encompasses large amount of information&lt;/li&gt;
&lt;li&gt;Consists of a variety of data types and formats&lt;/li&gt;
&lt;li&gt;Generated by disparate sources&lt;/li&gt;
&lt;li&gt;Retained for long periods&lt;/li&gt;
&lt;li&gt;Utilized by new and innovative applications&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sources of Big data: web browsing, purchasing, social media, docs, genomic data, GPS, sensors …&lt;/li&gt;
&lt;li&gt;Datafication: turning many aspects of our life into computerised forms of new meaning and forms of value.&lt;/li&gt;
&lt;li&gt;IoT: Internet of Things&lt;/li&gt;
&lt;li&gt;Issues:&lt;ul&gt;
&lt;li&gt;Security/Privacy&lt;/li&gt;
&lt;li&gt;Rigor&lt;/li&gt;
&lt;li&gt;Timing&lt;/li&gt;
&lt;li&gt;Comprehensiveness&lt;/li&gt;
&lt;li&gt;Standards&lt;/li&gt;
&lt;li&gt;Sampling&lt;/li&gt;
&lt;li&gt;Utilization&lt;/li&gt;
&lt;li&gt;Too much data&lt;ul&gt;
&lt;li&gt;Benefit of Big Data&lt;/li&gt;
&lt;li&gt;Combine multiple sources of data&lt;/li&gt;
&lt;li&gt;Exploit unstructured data&lt;/li&gt;
&lt;li&gt;Provide insights &lt;/li&gt;
&lt;li&gt;Quicker action&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;What-is-Data-Science&quot;&gt;&lt;a href=&quot;#What-is-Data-Science&quot; class=&quot;headerlink&quot; title=&quot;What is Data Science&quot;&gt;&lt;/a&gt;What is Data Science&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Math, Algorithms, Coding, Subject matter&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Concentration areas:&lt;ul&gt;
&lt;li&gt;Spatial analysis&lt;/li&gt;
&lt;li&gt;text mining&lt;/li&gt;
&lt;li&gt;Speech&lt;/li&gt;
&lt;li&gt;Social media&lt;/li&gt;
&lt;li&gt;Big Data&lt;/li&gt;
&lt;li&gt;Medical&lt;/li&gt;
&lt;li&gt;Bioinformatics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Process steps:&lt;ul&gt;
&lt;li&gt;Question&lt;ul&gt;
&lt;li&gt;data acquisition&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data&lt;ul&gt;
&lt;li&gt;data processing, data management, data storage, data retrieval&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Methods&lt;ul&gt;
&lt;li&gt;data mining, machine learning, regression&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Inference&lt;ul&gt;
&lt;li&gt;computational statistics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Presentation &lt;ul&gt;
&lt;li&gt;visualization, data graphic design&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Answer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tools&lt;ul&gt;
&lt;li&gt;Data mining tool – Weka&lt;/li&gt;
&lt;li&gt;Scratch analyses – homegrown and open-source libraries in R, Python, Java etc.&lt;/li&gt;
&lt;li&gt;Visualizing – Qlikview, Tableau, periscope.io&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      Basic concept of Big Data and useful resources about Big Data.
    
    </summary>
    
      <category term="Database" scheme="http://zhaot777.github.io/categories/Database/"/>
    
    
      <category term="Database, Big Data, Curriculum Review" scheme="http://zhaot777.github.io/tags/Database-Big-Data-Curriculum-Review/"/>
    
  </entry>
  
  <entry>
    <title>NoSQL Review</title>
    <link href="http://zhaot777.github.io/2016/06/19/DB_NoSQL/"/>
    <id>http://zhaot777.github.io/2016/06/19/DB_NoSQL/</id>
    <published>2016-06-19T23:37:11.871Z</published>
    <updated>2016-06-19T23:53:37.381Z</updated>
    
    <content type="html">&lt;h3 id=&quot;What-is-NoSQL&quot;&gt;&lt;a href=&quot;#What-is-NoSQL&quot; class=&quot;headerlink&quot; title=&quot;What is NoSQL&quot;&gt;&lt;/a&gt;What is NoSQL&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Need for NoSQL&lt;ul&gt;
&lt;li&gt;Lots of new and new types of data&lt;/li&gt;
&lt;li&gt;Hard to use a relational model&lt;/li&gt;
&lt;li&gt;Hard to scale up to fit more data, more users&lt;/li&gt;
&lt;li&gt;Hard to keep up performance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Feature: flexible, schema-less, efficient &amp;amp; fast, available, scalable&lt;/li&gt;
&lt;li&gt;JSON: a set of key-value pairs&lt;/li&gt;
&lt;li&gt;‘BASE’ property&lt;ul&gt;
&lt;li&gt;Best effort&lt;/li&gt;
&lt;li&gt;Approximate answer&lt;/li&gt;
&lt;li&gt;Simpler&lt;/li&gt;
&lt;li&gt;Easier evolution&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;NoSQL-DBs&quot;&gt;&lt;a href=&quot;#NoSQL-DBs&quot; class=&quot;headerlink&quot; title=&quot;NoSQL DBs&quot;&gt;&lt;/a&gt;NoSQL DBs&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Types: Key-value store, Column-family store, Document store, Graph store&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Standard way to compare NoSQL DBs: Architecture, administration, deployment, development, performance &amp;amp; scalability&lt;/li&gt;
&lt;li&gt;Polyglot persistence: use different storage technologies to store different parts of a single application and tied together by the application, using DB APIs or web services APIs.&lt;/li&gt;
&lt;li&gt;NoSQL benefit&lt;ul&gt;
&lt;li&gt;Improve programmer productivity, better matches needs&lt;/li&gt;
&lt;li&gt;Improve data access performance, large volumes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Node &amp;amp; Cluster: Node is a single NoSQL DB instance, Cluster is a collection of nodes which holds an entire DB.&lt;/li&gt;
&lt;li&gt;Key-value DBs&lt;ul&gt;
&lt;li&gt;While DB is a dictionary&lt;/li&gt;
&lt;li&gt;Records don’t have to contain identical fields&lt;/li&gt;
&lt;li&gt;Key is comparable to a PK. Value is an aggregate of all the dependent columns.&lt;/li&gt;
&lt;li&gt;Querying occurs only on keys, and entire value is returned.&lt;/li&gt;
&lt;li&gt;Memcached: distributed memory object caching system, simple&lt;/li&gt;
&lt;li&gt;Redis: offers richer types such as list, set and dictionary for values, and AlSO offer a way to use hashing for storing keys&lt;/li&gt;
&lt;li&gt;Anazon’s Dynamo&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Column family DBs&lt;ul&gt;
&lt;li&gt;BigTable, HBase, Cassandra, Amazon SimpleDB, Hypertable.&lt;/li&gt;
&lt;li&gt;Column family, Column, Super column family&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Document DBs&lt;ul&gt;
&lt;li&gt;A more sophisticated version of a key-value store, whre the value is a collection of documents, can be JSON, XML, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Graph DBs&lt;ul&gt;
&lt;li&gt;Use nodes, relations, properties(k-v pairs) on vertices and edges to store data.&lt;/li&gt;
&lt;li&gt;index free &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Triple store(Resource Description Framework)&lt;ul&gt;
&lt;li&gt;subject, predicate, object&lt;/li&gt;
&lt;li&gt;class, attribute, value  &lt;/li&gt;
&lt;li&gt;Architecture mode: in-memory, native store, non-native store(use third-party service)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      Basic concept of NoSQL and 4 types of NoSQL Databases
    
    </summary>
    
      <category term="Database" scheme="http://zhaot777.github.io/categories/Database/"/>
    
    
      <category term="Database, NoSQL, Curriculum Review" scheme="http://zhaot777.github.io/tags/Database-NoSQL-Curriculum-Review/"/>
    
  </entry>
  
  <entry>
    <title>Database Performance-Tuning Review</title>
    <link href="http://zhaot777.github.io/2016/06/19/DB_PerformanceTuning/"/>
    <id>http://zhaot777.github.io/2016/06/19/DB_PerformanceTuning/</id>
    <published>2016-06-19T23:37:11.870Z</published>
    <updated>2016-06-19T23:53:22.510Z</updated>
    
    <content type="html">&lt;h3 id=&quot;Performance-Tuning-concepts&quot;&gt;&lt;a href=&quot;#Performance-Tuning-concepts&quot; class=&quot;headerlink&quot; title=&quot;Performance-Tuning concepts&quot;&gt;&lt;/a&gt;Performance-Tuning concepts&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Set of activities and procedures that reduce response time of database system- Fine -tuning the performance of a system requires that all factors must operate at optimum level with minimal bottlenecks&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;All data in a database are stored in data files, and logical grouped similar characteristics data in file groups or table spaces&lt;/li&gt;
&lt;li&gt;Data cache or buffer cache: stores most recently accessed data blocks in RAM&lt;/li&gt;
&lt;li&gt;SQL cache or procedure cache: Stores most recently executed SQL statements or PL/SQL procedures&lt;/li&gt;
&lt;li&gt;Majority of performance-tuning activities focus on minimizing I/O operations between RAM and permanent storage&lt;/li&gt;
&lt;li&gt;Automatic query optimization &amp;amp; Manual query optimization&lt;/li&gt;
&lt;li&gt;Static query optimization &amp;amp; Dynamic query optimization&lt;/li&gt;
&lt;li&gt;Statistically based query optimization algorithm &amp;amp; Rule-based query optimization algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;DBMS-processes-SQL-queries&quot;&gt;&lt;a href=&quot;#DBMS-processes-SQL-queries&quot; class=&quot;headerlink&quot; title=&quot;DBMS processes SQL queries&quot;&gt;&lt;/a&gt;DBMS processes SQL queries&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Query Processing:&lt;ul&gt;
&lt;li&gt;Parsing: Query Optimizer chooses the most efficient access plan&lt;/li&gt;
&lt;li&gt;Execution: Reuse the exists cache plan or execute the SQL using the chosen execution plan&lt;/li&gt;
&lt;li&gt;Fetching: DBMS fetches the data and sends the result set back to the client    &lt;h3 id=&quot;Indexes&quot;&gt;&lt;a href=&quot;#Indexes&quot; class=&quot;headerlink&quot; title=&quot;Indexes&quot;&gt;&lt;/a&gt;Indexes&lt;/h3&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Help speed up data access&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Data sparsity: number of different values a cloumn could have. low sparsity make index might be useless&lt;/li&gt;
&lt;li&gt;Data structures used to implement indexed:&lt;ul&gt;
&lt;li&gt;Hash indexed&lt;/li&gt;
&lt;li&gt;B-tree indexed&lt;/li&gt;
&lt;li&gt;Bitmap indexed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Index Selectivity: Measure of the likelihood that an index will be used in query processing&lt;ul&gt;
&lt;li&gt;Index cannot always be used to improve performance&lt;/li&gt;
&lt;li&gt;Function-based index&lt;h3 id=&quot;Query-Optimizer&quot;&gt;&lt;a href=&quot;#Query-Optimizer&quot; class=&quot;headerlink&quot; title=&quot;Query Optimizer&quot;&gt;&lt;/a&gt;Query Optimizer&lt;/h3&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Optimizer Choices&lt;ul&gt;
&lt;li&gt;Rule-based optimizer &lt;/li&gt;
&lt;li&gt;Cost-based optimizer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Optimizer hints: special instructions for the optimizer, embedded in the SQL command text&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Formulate-Queries-and-tune-the-DBMS-for-optimal-performance&quot;&gt;&lt;a href=&quot;#Formulate-Queries-and-tune-the-DBMS-for-optimal-performance&quot; class=&quot;headerlink&quot; title=&quot;Formulate Queries and tune the DBMS for optimal performance&quot;&gt;&lt;/a&gt;Formulate Queries and tune the DBMS for optimal performance&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Find a good way to construct a SQL query&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Using RAID(Redundant Array of Independent Disks)&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      Performance-Tuning concepts, how DBMS processes SQL queries, and different way to tuning performance.
    
    </summary>
    
      <category term="Database" scheme="http://zhaot777.github.io/categories/Database/"/>
    
    
      <category term="Database, Curriculum Review" scheme="http://zhaot777.github.io/tags/Database-Curriculum-Review/"/>
    
  </entry>
  
  <entry>
    <title>Database Transaction Review</title>
    <link href="http://zhaot777.github.io/2016/06/19/DB_Transaction/"/>
    <id>http://zhaot777.github.io/2016/06/19/DB_Transaction/</id>
    <published>2016-06-19T23:37:11.868Z</published>
    <updated>2016-06-19T23:53:21.595Z</updated>
    
    <content type="html">&lt;h3 id=&quot;Database-Transactions&quot;&gt;&lt;a href=&quot;#Database-Transactions&quot; class=&quot;headerlink&quot; title=&quot;Database Transactions&quot;&gt;&lt;/a&gt;Database Transactions&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Logical unit of work that must be entirely completed or aborted&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Consistent database state: all data integrity constraints are satisfied&lt;/li&gt;
&lt;li&gt;Formed by two or more database requests, and it should equivalent of a single SQL statement in an application program or transaction&lt;/li&gt;
&lt;li&gt;ACID&lt;ul&gt;
&lt;li&gt;Atomicity&lt;/li&gt;
&lt;li&gt;Consistency&lt;/li&gt;
&lt;li&gt;Isolation&lt;/li&gt;
&lt;li&gt;Durability&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Transaction Management with SQL&lt;ul&gt;
&lt;li&gt;COMMIT&lt;/li&gt;
&lt;li&gt;ROLLBACK&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Transaction Log&lt;ul&gt;
&lt;li&gt;Keep track of all transactions that update the database&lt;/li&gt;
&lt;li&gt;For recovery requirement triggered by a ROLLBACK statement&lt;/li&gt;
&lt;li&gt;A program’s abnormal termination&lt;/li&gt;
&lt;li&gt;A system failure&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Concurrency-control&quot;&gt;&lt;a href=&quot;#Concurrency-control&quot; class=&quot;headerlink&quot; title=&quot;Concurrency control&quot;&gt;&lt;/a&gt;Concurrency control&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Ensure serializability of transactions in a multiuser database environment&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Problems &lt;ul&gt;
&lt;li&gt;Lost update: update same data&lt;/li&gt;
&lt;li&gt;Uncommitted data: one accessed uncommitted data, the other one rolled back&lt;/li&gt;
&lt;li&gt;Inconsistent retrievals: transaction accesses on some data other is working on&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Serializable schedule: Interleaved execution of transactions yields the same results as the serial execution of the transactions &lt;/li&gt;
&lt;li&gt;Locking methods &lt;ul&gt;
&lt;li&gt;Type    &lt;ul&gt;
&lt;li&gt;Binary Lock&lt;/li&gt;
&lt;li&gt;Exclusive Lock(write)&lt;/li&gt;
&lt;li&gt;Shared Lock(read)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Two-Phase Locking(2PL)&lt;ul&gt;
&lt;li&gt;Defines how transactions acquire and relinquish locks, guarantees seralizability but does not prevent deadlocks&lt;/li&gt;
&lt;li&gt;Growing phase - Transaction acquires all required locks without unlocking any data&lt;/li&gt;
&lt;li&gt;Shrinking phase - Transaction releases all locks and cannot obtain any new lock&lt;/li&gt;
&lt;li&gt;Rules&lt;ul&gt;
&lt;li&gt;Two transactions cannot have conflicting locks&lt;/li&gt;
&lt;li&gt;Cannot unlock before lock&lt;/li&gt;
&lt;li&gt;No data are affected until all locks are obtained&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stamping methods&lt;ul&gt;
&lt;li&gt;Assigns global, unique time stamp to each transaction&lt;/li&gt;
&lt;li&gt;Properties: Uniqueness &amp;amp; Monotonicity&lt;/li&gt;
&lt;li&gt;Disadvantages: increase memory, processing, resources, more fields&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Optimistic methods&lt;ul&gt;
&lt;li&gt;Transaction is validate to ensure that the changes made will not affect the integrity and consistency of the database&lt;/li&gt;
&lt;li&gt;Use data resources without acquiring locks on those resources&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      Transactions, and different Concurrency control approach.
    
    </summary>
    
      <category term="Database" scheme="http://zhaot777.github.io/categories/Database/"/>
    
    
      <category term="Database, Curriculum Review" scheme="http://zhaot777.github.io/tags/Database-Curriculum-Review/"/>
    
  </entry>
  
  <entry>
    <title>DB Normalization Review</title>
    <link href="http://zhaot777.github.io/2016/06/19/DB_Normalization/"/>
    <id>http://zhaot777.github.io/2016/06/19/DB_Normalization/</id>
    <published>2016-06-19T23:37:11.865Z</published>
    <updated>2016-06-19T23:53:43.233Z</updated>
    
    <content type="html">&lt;h3 id=&quot;What-is-normalization-and-what-role-it-plays-in-the-DB-design-process&quot;&gt;&lt;a href=&quot;#What-is-normalization-and-what-role-it-plays-in-the-DB-design-process&quot; class=&quot;headerlink&quot; title=&quot;What is normalization and what role it plays in the DB design process&quot;&gt;&lt;/a&gt;What is normalization and what role it plays in the DB design process&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Evaluating and correcting table structures to minimize data redundancies&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Reduces data anomalies&lt;/li&gt;
&lt;li&gt;Higher normal forms are better than lower normals forms and result in cleaner designs&lt;/li&gt;
&lt;li&gt;Properly designed 3NF structures meet the requirement of 4NF&lt;/li&gt;
&lt;li&gt;Normalization is a design step: Used to design a new DB structure or to improve the existing data structure &lt;/li&gt;
&lt;li&gt;Normalization Goal&lt;ul&gt;
&lt;li&gt;Each table represents a single subject&lt;/li&gt;
&lt;li&gt;No data item will be unnecessarily stored in more than one table&lt;/li&gt;
&lt;li&gt;All non-prime attribute in a table are dependent on the primary key&lt;/li&gt;
&lt;li&gt;Each table is void of insertion, update and deletion anomalies&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Normal-Forms&quot;&gt;&lt;a href=&quot;#Normal-Forms&quot; class=&quot;headerlink&quot; title=&quot;Normal Forms&quot;&gt;&lt;/a&gt;Normal Forms&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Characteristic&lt;ul&gt;
&lt;li&gt;1NF: Table format, no repeating groups, PK identified&lt;/li&gt;
&lt;li&gt;2NF: 1NF and no partial dependencies&lt;/li&gt;
&lt;li&gt;3NF: 2NF and no transitive dependencies&lt;/li&gt;
&lt;li&gt;4NF: 3NF and no independent multivalued dependencies&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Process&lt;ul&gt;
&lt;li&gt;Work on one relation at a time&lt;/li&gt;
&lt;li&gt;Identifying the dependencies of a relation&lt;/li&gt;
&lt;li&gt;Progressively breaking the relation into new set of relations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dependencies&lt;ul&gt;
&lt;li&gt;Functional Dependence: Each value of attribute A determines one and only one value of attribute B, then we say B is functionally dependent on A&lt;/li&gt;
&lt;li&gt;Partial Dependency: functional dependence in which the determinant is only part of the PK&lt;/li&gt;
&lt;li&gt;Transitive Dependency: An attribute functionally depends on another non-key attribute&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dependency diagram&lt;ul&gt;
&lt;li&gt;Mark PK&lt;/li&gt;
&lt;li&gt;Indicate full dependencies on the top and partial/transitive dependencies on the bottom&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;BCNF&lt;ul&gt;
&lt;li&gt;Candidate key: same as primary key but not chosen to be the primary key&lt;/li&gt;
&lt;li&gt;If the table contains more than one candidate key, it violated the BCNF, which is a special case of 3NF&lt;/li&gt;
&lt;li&gt;Solution: try to change the primary key and separate one relation to two&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Denormalization&quot;&gt;&lt;a href=&quot;#Denormalization&quot; class=&quot;headerlink&quot; title=&quot;Denormalization&quot;&gt;&lt;/a&gt;Denormalization&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Produces a lower normal form and increased performance and greater data redundancy&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      Basic concept of Database Normalization, normal forms and how to implement each forms.
    
    </summary>
    
      <category term="Database" scheme="http://zhaot777.github.io/categories/Database/"/>
    
    
      <category term="Database, Curriculum Review" scheme="http://zhaot777.github.io/tags/Database-Curriculum-Review/"/>
    
  </entry>
  
  <entry>
    <title>Memory Management Review</title>
    <link href="http://zhaot777.github.io/2016/05/15/memoryreview/"/>
    <id>http://zhaot777.github.io/2016/05/15/memoryreview/</id>
    <published>2016-05-15T19:12:35.285Z</published>
    <updated>2016-05-22T04:44:29.011Z</updated>
    
    <content type="html">&lt;h2 id=&quot;Virtual-Memory-Basic&quot;&gt;&lt;a href=&quot;#Virtual-Memory-Basic&quot; class=&quot;headerlink&quot; title=&quot;Virtual Memory Basic&quot;&gt;&lt;/a&gt;Virtual Memory Basic&lt;/h2&gt;&lt;h3 id=&quot;Virtual-Address-Concept&quot;&gt;&lt;a href=&quot;#Virtual-Address-Concept&quot; class=&quot;headerlink&quot; title=&quot;Virtual Address Concept&quot;&gt;&lt;/a&gt;Virtual Address Concept&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Protect processes from on another&lt;/li&gt;
&lt;li&gt;Protect the OS from user processes&lt;/li&gt;
&lt;li&gt;Provide efficient management of available storage&lt;/li&gt;
&lt;li&gt;Use a virtual address to address any memory location in the 32-bit address space&lt;/li&gt;
&lt;li&gt;Only headware use physical address(include processor) and OS manages the physical address space&lt;/li&gt;
&lt;li&gt;Memory Management Unit (MMU), is used for indirect address translation. It translated virtual address into physical address.&lt;br&gt;  &lt;img src=&quot;https://farm8.staticflickr.com/7534/26980709472_21687456f0_b.jpg&quot; width=&quot;400&quot; height=&quot;200&quot; alt=&quot;MMU&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Memory-Management-in-the-Early-Days&quot;&gt;&lt;a href=&quot;#Memory-Management-in-the-Early-Days&quot; class=&quot;headerlink&quot; title=&quot;Memory Management in the Early Days&quot;&gt;&lt;/a&gt;Memory Management in the Early Days&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Memory Fence&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If a user program tries to access OS area (address bigger than fence address) MMU will generate a trap    &lt;/li&gt;
&lt;li&gt;use overlays and resident to deal with user program won’t fit in memory&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Base and Bounds Registers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bounds register: Address space size of the user process&lt;/li&gt;
&lt;li&gt;Base register: Start of physical memory for the user process&lt;/li&gt;
&lt;li&gt;Segmentation:&lt;ul&gt;
&lt;li&gt;One pair of base and bounds registers per segment.&lt;/li&gt;
&lt;li&gt;code, data, heap, stack and may be more (Memory Mapped file).&lt;/li&gt;
&lt;li&gt;Use one bit to have access control (read-only, read/write).&lt;/li&gt;
&lt;li&gt;If two prcesses read same memory, they can share segments.&lt;/li&gt;
&lt;li&gt;Segmentation fault: virtual address not within range of any base-bounds registers or not valid.&lt;/li&gt;
&lt;li&gt;Copy-On-Write: a process gets private copy of the page after a thread in the process performs a write for the first time (private/share bit need not be inside MMU).&lt;/li&gt;
&lt;li&gt;Use a validity bit for each segment to find whether this segment is in memory or being swapped out before.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Hardware-Support-for-Virtual-Memory&quot;&gt;&lt;a href=&quot;#Hardware-Support-for-Virtual-Memory&quot; class=&quot;headerlink&quot; title=&quot;Hardware Support for Virtual Memory&quot;&gt;&lt;/a&gt;Hardware Support for Virtual Memory&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Segmentation divide the address space into variable-size segments and it has external fragmentation problem and “first-fit” is slow.&lt;/li&gt;
&lt;li&gt;Paging divede the address space into fixed-size pages and can have internal fragmentation problem.&lt;/li&gt;
&lt;li&gt;Paging:&lt;ul&gt;
&lt;li&gt;Address space is divided into pages, indexed by virtual page number.&lt;/li&gt;
&lt;li&gt;Basic (Two-level) Page table indexed by virtual page number, start with a physical address (this is stored in the CR3 register for X86), has validity, modified, reference and protect bit, and physical page number.&lt;/li&gt;
&lt;li&gt;A page table is associated with each process (OS has its page table as well).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Forward-Mapped-Multi-level-Page-Tables&quot;&gt;&lt;a href=&quot;#Forward-Mapped-Multi-level-Page-Tables&quot; class=&quot;headerlink&quot; title=&quot;Forward-Mapped (Multi-level) Page Tables&quot;&gt;&lt;/a&gt;Forward-Mapped (Multi-level) Page Tables&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://farm8.staticflickr.com/7400/27076290915_04e7cb14b9_b.jpg&quot; width=&quot;400&quot; height=&quot;220&quot; alt=&quot;FM page table&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use 10 bits for page dir table and 10 bits for page table and the last 12 bits use for offset.&lt;/li&gt;
&lt;li&gt;Can save page table size, the minimum size is 12KB (one page dir two page tables)&lt;/li&gt;
&lt;li&gt;The drawback is it has two physical memory accesses to map a virtual address to a physical address&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Linear-Page-Tables&quot;&gt;&lt;a href=&quot;#Linear-Page-Tables&quot; class=&quot;headerlink&quot; title=&quot;Linear Page Tables&quot;&gt;&lt;/a&gt;Linear Page Tables&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Use 2 bit as Space, 00 and 01 page table are start with virtual address space and conbine the 00 or 01 bits, in 10 space page table started with physical address we can find page table entry.&lt;/li&gt;
&lt;li&gt;Can reduce size requirements with partial page tables, and it can use length register to constranins size of each space. But it not work well for multiple processes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Hashed-Page-Tables&quot;&gt;&lt;a href=&quot;#Hashed-Page-Tables&quot; class=&quot;headerlink&quot; title=&quot;Hashed Page Tables&quot;&gt;&lt;/a&gt;Hashed Page Tables&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Hashed page tables&lt;ul&gt;
&lt;li&gt;Use 2 bits for hashing&lt;/li&gt;
&lt;li&gt;Works well for sparcely allocated address space&lt;/li&gt;
&lt;li&gt;Each page table entry have a tag and link&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Clustered page tables&lt;ul&gt;
&lt;li&gt;Many page table entries have one tag and link&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Inverted page tables&lt;ul&gt;
&lt;li&gt;Page table is indexed by physical page number&lt;/li&gt;
&lt;li&gt;Conbine virtual page number and PID to get hash&lt;/li&gt;
&lt;li&gt;Each entry contains PID, page number and physical page number&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Translation-Lookaside-Buffers-TLB&quot;&gt;&lt;a href=&quot;#Translation-Lookaside-Buffers-TLB&quot; class=&quot;headerlink&quot; title=&quot;Translation Lookaside Buffers (TLB)&quot;&gt;&lt;/a&gt;Translation Lookaside Buffers (TLB)&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Cashe page table entries, caches the mapping from virtual page nmber to physical page number.&lt;/li&gt;
&lt;li&gt;TLB miss will cost O(1) memory accesses.&lt;/li&gt;
&lt;li&gt;When a page table entry is modified, the OS must flush (invalidate) the corresponding TLB entry. When switching to a different process, must flush the entire TLB.&lt;/li&gt;
&lt;li&gt;In a multiprocessors environment, one processor can modify a mapping cached in the TLB of another processor by shoot-down (invalidate) the another processor.&lt;/li&gt;
&lt;li&gt;Two-way set-associative cache with 64 lines:    &lt;ul&gt;
&lt;li&gt;Use 6 bits as key to have 64 lines.&lt;/li&gt;
&lt;li&gt;In same the line, tag in the virtual address is used to compared against all other tags in same line simutaneously.&lt;/li&gt;
&lt;li&gt;For other TLB, it can be fully associative cache or one-way set- associative cache.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;64-Bit-Issues&quot;&gt;&lt;a href=&quot;#64-Bit-Issues&quot; class=&quot;headerlink&quot; title=&quot;64-Bit Issues&quot;&gt;&lt;/a&gt;64-Bit Issues&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Have more tables which need more physical memory accesses to map a virtual address to a physical address&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Virtualization-virtualizing-virtual-memory&quot;&gt;&lt;a href=&quot;#Virtualization-virtualizing-virtual-memory&quot; class=&quot;headerlink&quot; title=&quot;Virtualization (virtualizing virtual memory)&quot;&gt;&lt;/a&gt;Virtualization (virtualizing virtual memory)&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Can use shadow page table, when a VM changes its page table, VMM must update the corresponding shadow page table. But it has poor per formance.&lt;/p&gt;
&lt;p&gt;  &lt;img src=&quot;https://farm8.staticflickr.com/7427/26982039952_1efe21c539_o.png&quot; width=&quot;400&quot; height=&quot;220&quot; alt=&quot;shadow page table&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use Extended Page Tables, two table in sequence and does the conversion all by itself.&lt;/p&gt;
&lt;p&gt;  &lt;img src=&quot;https://farm8.staticflickr.com/7675/26472922783_48b1352333_b.jpg&quot; width=&quot;400&quot; height=&quot;250&quot; alt=&quot;shadow page table&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Operating-System-Issues&quot;&gt;&lt;a href=&quot;#Operating-System-Issues&quot; class=&quot;headerlink&quot; title=&quot;Operating System Issues&quot;&gt;&lt;/a&gt;Operating System Issues&lt;/h2&gt;&lt;h3 id=&quot;General-Concerns&quot;&gt;&lt;a href=&quot;#General-Concerns&quot; class=&quot;headerlink&quot; title=&quot;General Concerns&quot;&gt;&lt;/a&gt;General Concerns&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Prefetching    &lt;ul&gt;
&lt;li&gt;Fetching a page as well as the sequential pages.&lt;/li&gt;
&lt;li&gt;Access to pages is often sequential.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pageout Daemon&lt;ul&gt;
&lt;li&gt;Reference bit in page table entry is used for approximate LRU.&lt;/li&gt;
&lt;li&gt;Clock algorthm, need to give enough time for thousands of references before checking&lt;br&gt;&lt;img src=&quot;https://farm8.staticflickr.com/7366/26982432522_b89cb1fe31_b.jpg&quot; width=&quot;420&quot; height=&quot;280&quot; alt=&quot;Clock algorthm&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Thrashing problem&lt;ul&gt;
&lt;li&gt;Global allocation: All processes compete for page frames from a single pool.&lt;/li&gt;
&lt;li&gt;Local allocation: Each process has its own private pool of page frames. Using Local Allocation is a way to reduce the chance of thrashing.&lt;/li&gt;
&lt;li&gt;For thrashing problem, use Working-Set Principle, if the sum of the working-set of all processes is less than the total amount of available physical memory then thrashing cannot occur.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Representative-Systems&quot;&gt;&lt;a href=&quot;#Representative-Systems&quot; class=&quot;headerlink&quot; title=&quot;Representative Systems&quot;&gt;&lt;/a&gt;Representative Systems&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Address-Space Simplified Representation:    &lt;/p&gt;
&lt;p&gt;  &lt;img src=&quot;https://farm8.staticflickr.com/7728/27008966701_abf3d06926_b.jpg&quot; width=&quot;420&quot; height=&quot;250&quot; alt=&quot;AS simple pres&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Address-Space Real Representation:&lt;/p&gt;
&lt;p&gt;  &lt;img src=&quot;https://farm8.staticflickr.com/7195/27008966741_f2cc810af9_b.jpg&quot; width=&quot;420&quot; height=&quot;270&quot; alt=&quot;AS real pres&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Copy-on-Write-and-Fork&quot;&gt;&lt;a href=&quot;#Copy-on-Write-and-Fork&quot; class=&quot;headerlink&quot; title=&quot;Copy on Write and Fork&quot;&gt;&lt;/a&gt;Copy on Write and Fork&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Shadow Objects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Keep track of pages that were originally copy-on-write but have benn modified.&lt;/li&gt;
&lt;li&gt;A page in a memory map, into which an object was mapped private, have an associated shadow object.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Shadow object tells you where to copy from when you need to perform copy-on-write.&lt;/p&gt;
&lt;p&gt;  &lt;img src=&quot;https://farm8.staticflickr.com/7431/26473555803_b050ed08d4_b.jpg&quot; width=&quot;420&quot; height=&quot;250&quot; alt=&quot;Clock algorthm&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Backing-Store-Issues&quot;&gt;&lt;a href=&quot;#Backing-Store-Issues&quot; class=&quot;headerlink&quot; title=&quot;Backing Store Issues&quot;&gt;&lt;/a&gt;Backing Store Issues&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Shadow objects and anonymous memory must be backed up in swap space.&lt;/li&gt;
&lt;li&gt;Swap Space management approach:    &lt;ul&gt;
&lt;li&gt;randical-conservative approach: eager evaluation, backing-store space is allocated when virtual memory is allocated.&lt;/li&gt;
&lt;li&gt;radical-liberal approach: lazy evaluation, backing-store space is allocated only when needed.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Go to www.addthis.com/dashboard to customize your tools --&gt;
&lt;div class=&quot;addthis_sharing_toolbox&quot;&gt;&lt;/div&gt;</content>
    
    <summary type="html">
    
      This is a review of memory management, and focus on virtual address concept, different ways of memory management, TLB, shadow object, backing store issues.
    
    </summary>
    
      <category term="Operating Systems" scheme="http://zhaot777.github.io/categories/Operating-Systems/"/>
    
    
      <category term="OS, virtual memory" scheme="http://zhaot777.github.io/tags/OS-virtual-memory/"/>
    
  </entry>
  
  <entry>
    <title>File Systems Review</title>
    <link href="http://zhaot777.github.io/2016/05/12/filesystemsreview/"/>
    <id>http://zhaot777.github.io/2016/05/12/filesystemsreview/</id>
    <published>2016-05-13T06:01:40.051Z</published>
    <updated>2016-05-13T19:05:58.235Z</updated>
    
    <content type="html">&lt;h3 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h3&gt;&lt;p&gt;The requirements of file systems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Permanent storage&lt;/li&gt;
&lt;li&gt;Quick, easy and efficient&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;The-Basics-of-File-Systems&quot;&gt;&lt;a href=&quot;#The-Basics-of-File-Systems&quot; class=&quot;headerlink&quot; title=&quot;The Basics of File Systems&quot;&gt;&lt;/a&gt;The Basics of File Systems&lt;/h3&gt;&lt;h4 id=&quot;Disk-Architecture&quot;&gt;&lt;a href=&quot;#Disk-Architecture&quot; class=&quot;headerlink&quot; title=&quot;Disk Architecture&quot;&gt;&lt;/a&gt;Disk Architecture&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;https://farm8.staticflickr.com/7587/26889680562_7ae35ccfab_h.jpg&quot; width=&quot;400&quot; height=&quot;280&quot; alt=&quot;disk_architecture&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Have multiple platters and each one have top and bottom heads.&lt;/li&gt;
&lt;li&gt;The smallest addressable unit is a sector. Each platter contains many tracks and each track contains many sectors. The same vertical’s tracks is one cylinder.&lt;/li&gt;
&lt;li&gt;disk address = (head/surface#, cylinder/track#, sector#)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;S5FS&quot;&gt;&lt;a href=&quot;#S5FS&quot; class=&quot;headerlink&quot; title=&quot;S5FS&quot;&gt;&lt;/a&gt;S5FS&lt;/h4&gt;&lt;p&gt;Simple, slow, don’t terribly tolerant to crashes, reasonably efficient in space although no compression&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;layout&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://farm8.staticflickr.com/7671/26983710105_ec8f5d2828_b.jpg&quot; width=&quot;170&quot; height=&quot;250&quot; alt=&quot;S5FS&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The layout of the disk simply an array of blocks of 1KB each and it starts with Boot block, Superblock and then it contains i-list, which has many blocks and keep all the inode information. The final part is Data Region, which keep all the real data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Superblock&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Contains the head of the free list:&lt;br&gt;  Can address up to 100 free disk blocks, and the last pointer point to additional free disk blocks, etc.&lt;/li&gt;
&lt;li&gt;Maintain a free inode list (inode cache):&lt;br&gt;  Caches free inode. When allocate an inode, just remove it from cache and mark in the i-list not free.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I-list&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For each inode, it contains: Device, Inode Number, Mode, Link Count, Owner and Group, Size, Disk Map&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Disk map&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://farm8.staticflickr.com/7031/26950370586_6eea21b2b0_h.jpg&quot; width=&quot;450&quot; height=&quot;320&quot; alt=&quot;Disk map&quot;&gt;&lt;/p&gt;
&lt;p&gt; 0~9 each point to a data block, 10 point to a block which contains 256 max entries and each entry point to a data block, and 11 have one more layer and 12 have two more layer.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Improvement-of-S5FS&quot;&gt;&lt;a href=&quot;#Improvement-of-S5FS&quot; class=&quot;headerlink&quot; title=&quot;Improvement of S5FS&quot;&gt;&lt;/a&gt;Improvement of S5FS&lt;/h4&gt;&lt;p&gt;Rhinopias’s S5SF have very low effective transfer speed. We need to improve access time (seek time + rotatinal latency + data transfer time)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Increase block size&lt;/li&gt;
&lt;li&gt;Minimizing seek time&lt;ul&gt;
&lt;li&gt;Use cylinder groups to put related data in the same cylinde group&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Minimizing Latency&lt;ul&gt;
&lt;li&gt;Block interleaving&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Log-Structured File System (LFS)&lt;/p&gt;
&lt;p&gt;  &lt;img src=&quot;https://farm8.staticflickr.com/7040/26388472283_d457c0580f_b.jpg&quot; width=&quot;400&quot; height=&quot;100&quot; alt=&quot;LFS&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Main principles: nerver delete, append only.&lt;/li&gt;
&lt;li&gt;Inode Map: keep the updated inode, and each inode map piece is appended to log. &lt;/li&gt;
&lt;li&gt;Use checkpoint file (can have previous and current version) which is not belong to log to keeps track of all inode map pieces.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Multiple-Disks&quot;&gt;&lt;a href=&quot;#Multiple-Disks&quot; class=&quot;headerlink&quot; title=&quot;Multiple Disks&quot;&gt;&lt;/a&gt;Multiple Disks&lt;/h3&gt;&lt;h4 id=&quot;Benefits-of-Multiple-Disks&quot;&gt;&lt;a href=&quot;#Benefits-of-Multiple-Disks&quot; class=&quot;headerlink&quot; title=&quot;Benefits of Multiple Disks&quot;&gt;&lt;/a&gt;Benefits of Multiple Disks&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Hold more data&lt;/li&gt;
&lt;li&gt;Can be stored redundantly, increase reliability and availability&lt;/li&gt;
&lt;li&gt;Can spread data, allowing parallel access, increase effective access time&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Logical-Volume-Manager-LVM&quot;&gt;&lt;a href=&quot;#Logical-Volume-Manager-LVM&quot; class=&quot;headerlink&quot; title=&quot;Logical Volume Manager (LVM)&quot;&gt;&lt;/a&gt;Logical Volume Manager (LVM)&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;https://farm8.staticflickr.com/7711/26950370436_e841701895_o.png&quot; width=&quot;350&quot; height=&quot;150&quot; alt=&quot;LVM&quot;&gt;&lt;/p&gt;
&lt;p&gt;Manage multiple disks and try not change existing file systems much.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spanning: Multiple disks appear to file system as one large disk&lt;/li&gt;
&lt;li&gt;Mirroring: Write redundantly to multiple disks. Read from one.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Striping&quot;&gt;&lt;a href=&quot;#Striping&quot; class=&quot;headerlink&quot; title=&quot;Striping&quot;&gt;&lt;/a&gt;Striping&lt;/h4&gt;&lt;p&gt;One disk keep one striping unit data and then the next disk keep next one string unit data and keep doing this.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Advantages: Increase parallelism.&lt;/li&gt;
&lt;li&gt;Disadvantages: Worse reliability, higher variance and heterogenious disks will reduce the saving access time.&lt;/li&gt;
&lt;li&gt;In general, performance is better with larger striping unit, which can reduce seek time&lt;/li&gt;
&lt;li&gt;Probability of N-disk system failing is: 1-(1-fail)^N&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Redundant-Array-of-Inexpensive-Disks-RAID&quot;&gt;&lt;a href=&quot;#Redundant-Array-of-Inexpensive-Disks-RAID&quot; class=&quot;headerlink&quot; title=&quot;Redundant Array of Inexpensive Disks (RAID)&quot;&gt;&lt;/a&gt;Redundant Array of Inexpensive Disks (RAID)&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;level 1: Just mirroring.&lt;/li&gt;
&lt;li&gt;level 2: Similar to memory’s ECC, use serveal disks to check bits.&lt;/li&gt;
&lt;li&gt;level 3: Use one disk to maintain parity bits.&lt;/li&gt;
&lt;li&gt;level 4: Use one disk to maintain parity blocks.&lt;/li&gt;
&lt;li&gt;level 5: Solve level 4’s problem about write performance bottleneck that has no special disk to maintain parity blocks and spread parity blocks to all disks.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Flash-Memory&quot;&gt;&lt;a href=&quot;#Flash-Memory&quot; class=&quot;headerlink&quot; title=&quot;Flash Memory&quot;&gt;&lt;/a&gt;Flash Memory&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Technologies of Flash&lt;ul&gt;
&lt;li&gt;NOR: Byte addressable.&lt;/li&gt;
&lt;li&gt;NAND: Page addressable, cheaper but has limit on P/E cycle, about 10000.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Wear leveling&lt;ul&gt;
&lt;li&gt;Writing problem: To change zeroes to ones, must erase entire block.&lt;/li&gt;
&lt;li&gt;Spread writes/erasures across entire drive.&lt;/li&gt;
&lt;li&gt;Using flash traslation layer(FTL) and log-structured file system.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;Crash-Resiliency&quot;&gt;&lt;a href=&quot;#Crash-Resiliency&quot; class=&quot;headerlink&quot; title=&quot;Crash Resiliency&quot;&gt;&lt;/a&gt;Crash Resiliency&lt;/h3&gt;&lt;h4 id=&quot;Crash-problem&quot;&gt;&lt;a href=&quot;#Crash-problem&quot; class=&quot;headerlink&quot; title=&quot;Crash problem&quot;&gt;&lt;/a&gt;Crash problem&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Disk update, gather all dirty blocks, which is done one disk block at a time.&lt;/li&gt;
&lt;li&gt;In S5fs and FFS, the lower level file system can sequence disk writes in any order.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Dealing-with-Crashes&quot;&gt;&lt;a href=&quot;#Dealing-with-Crashes&quot; class=&quot;headerlink&quot; title=&quot;Dealing with Crashes&quot;&gt;&lt;/a&gt;Dealing with Crashes&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Soft Updates&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Consistency-preserving approach: order disk operations to preserve meta-data consistency.&lt;/li&gt;
&lt;li&gt;Have problems. In reality, in order to save the numver of disk writes, multiple objects can be packed into a diks block and will make a cycle in the topological order, and breaking circular dependency will slow the preformance.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Journaling&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://farm8.staticflickr.com/7251/26387400194_a85f1f718a_b.jpg&quot; width=&quot;400&quot; height=&quot;60&quot; alt=&quot;journaling&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use transaction idea, a journal is append-only, and it is a separate part of the disk(can add to any file system).&lt;/li&gt;
&lt;li&gt;Append a commit record, when it’s time to update the file system, write to journal first, and write data to file system only after the commit record is writeen to the journal.&lt;/li&gt;
&lt;li&gt;Undo journaling(record previous contents), redo journaling(record new contents).&lt;/li&gt;
&lt;li&gt;Recovery will take the file system into a consistent state at a transaction boundary, and copying a disk block to the file system is idempotent.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Shadow paging&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Based on copy-on-write ideas&lt;/p&gt;
&lt;p&gt;  &lt;img src=&quot;https://farm8.staticflickr.com/7589/26387505004_aabd34527c_b.jpg&quot; width=&quot;400&quot; height=&quot;240&quot; alt=&quot;shadow_paging&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;Naming-and-Directories&quot;&gt;&lt;a href=&quot;#Naming-and-Directories&quot; class=&quot;headerlink&quot; title=&quot;Naming and Directories&quot;&gt;&lt;/a&gt;Naming and Directories&lt;/h3&gt;&lt;h4 id=&quot;Directories&quot;&gt;&lt;a href=&quot;#Directories&quot; class=&quot;headerlink&quot; title=&quot;Directories&quot;&gt;&lt;/a&gt;Directories&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;S5FS Directories&lt;ul&gt;
&lt;li&gt;Each entry is 32 bytes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;FFS Directories:&lt;ul&gt;
&lt;li&gt;No restrictions on names.&lt;/li&gt;
&lt;li&gt;Maintain the last entry to get the free space.&lt;/li&gt;
&lt;li&gt;Use Hash table or B+ tree to look for a file name.&lt;/li&gt;
&lt;li&gt;Use extensible Hashing, the low-order i bits of hi(x) are the same in hi+1(x)&lt;/li&gt;
&lt;li&gt;B+ tree, internal nodes contain no data, just keys, leaf node are linked to ease sorted sequential traversal&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Name-Space-Management&quot;&gt;&lt;a href=&quot;#Name-Space-Management&quot; class=&quot;headerlink&quot; title=&quot;Name-Space Management&quot;&gt;&lt;/a&gt;Name-Space Management&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;For Windows, it use drives to make the name-space appear uniform. For Unix, it use file system mounting.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;File-systems-Summary&quot;&gt;&lt;a href=&quot;#File-systems-Summary&quot; class=&quot;headerlink&quot; title=&quot;File systems Summary&quot;&gt;&lt;/a&gt;File systems Summary&lt;/h3&gt;&lt;p&gt;This is a review of file systems, and focus on S5FS, multiple disks, flash memory, crash Resiliency, naming and dirctories.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://farm8.staticflickr.com/7240/26387779154_5758d2a7f6_b.jpg&quot; width=&quot;450&quot; height=&quot;280&quot; alt=&quot;file_system_summary&quot;&gt;&lt;/p&gt;
&lt;!-- Go to www.addthis.com/dashboard to customize your tools --&gt;
&lt;div class=&quot;addthis_sharing_toolbox&quot;&gt;&lt;/div&gt;
</content>
    
    <summary type="html">
    
      This is a review of file systems, and focus on S5FS, multiple disks, flash memory, crash Resiliency, naming and dirctories.
    
    </summary>
    
      <category term="Operating Systems" scheme="http://zhaot777.github.io/categories/Operating-Systems/"/>
    
    
      <category term="OS" scheme="http://zhaot777.github.io/tags/OS/"/>
    
  </entry>
  
  <entry>
    <title>To Do List</title>
    <link href="http://zhaot777.github.io/2016/03/18/todolist/"/>
    <id>http://zhaot777.github.io/2016/03/18/todolist/</id>
    <published>2016-03-18T08:17:14.614Z</published>
    <updated>2016-03-19T22:11:54.335Z</updated>
    
    <content type="html">&lt;figure&gt;&lt;br&gt;    &lt;img src=&quot;https://farm2.staticflickr.com/1604/25284321663_f4c97b9a5e_o.jpg&quot; width=&quot;863&quot; height=&quot;430&quot; alt=&quot;angular_bootstrap&quot;&gt;&lt;br&gt;&lt;/figure&gt;

&lt;h3 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;AngularJS&lt;/strong&gt; is an open-sourced web application JavaScript framework designed for Single Page Applications (SPA). An SPA is a web application or website that fits into a single web page. It is a design choice intended to provide a more fluid user experience. Angular’s data binding and dependency injection make your application’s components clear and succinct. If you are building a game or a computationally intensive math application, Angular may not fit your particular requirements, however, for generic web applications it should serve as a viable framework to build upon.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bootstrap&lt;/strong&gt; is a free front-end framework for faster and easier web development. It includes HTML and CSS based design templates for typography, forms, buttons, tables, navigation, modals, image carousels and many other, as well as optional JavaScript plugins. Bootstrap also gives you the ability to easily create responsive designs&lt;/p&gt;

&lt;h3 id=&quot;Instructions&quot;&gt;&lt;a href=&quot;#Instructions&quot; class=&quot;headerlink&quot; title=&quot;Instructions&quot;&gt;&lt;/a&gt;Instructions&lt;/h3&gt;&lt;p&gt;Implement a TODO list web application with the following functionality:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initial page with empty “TODO list”&lt;/li&gt;
&lt;li&gt;User has the ability to Add/Delete a TODO item&lt;/li&gt;
&lt;li&gt;User has the ability to mark one item as completed&lt;/li&gt;
&lt;li&gt;User has the ability to view TODO list items in different&lt;/li&gt;
&lt;li&gt;tabs based on the following states:&lt;ul&gt;
&lt;li&gt;All&lt;/li&gt;
&lt;li&gt;Active&lt;/li&gt;
&lt;li&gt;Completed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A search bar is provided, so that the user is able to search for a particular TODO item&lt;br&gt;Bonus Functionality&lt;br&gt;The user is only presented with the option to delete a TODO item when they are hovering the mouse over that item&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;To fit the requirement, we can use 2 panels, one for searching tasks and another one for adding tasks.&lt;/li&gt;
&lt;li&gt;For add, completed and delete, we can use controller to change the status of item in our data.&lt;/li&gt;
&lt;li&gt;For searching item, we can create a filter, when click the search button, show the filtered data.&lt;/li&gt;
&lt;li&gt;The tricky part is to synchronized the search list and data list, when we click the delete button in either of this list, we need to delete the the same item in another list.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;Demo-Display&quot;&gt;&lt;a href=&quot;#Demo-Display&quot; class=&quot;headerlink&quot; title=&quot;Demo Display&quot;&gt;&lt;/a&gt;Demo Display&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Initial page:&lt;br&gt;&lt;img src=&quot;https://farm2.staticflickr.com/1650/25601037730_045a9369af_o.png&quot; width=&quot;1666&quot; height=&quot;1042&quot; alt=&quot;todolist1&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt;After add tasks and do search:&lt;br&gt;&lt;img src=&quot;https://farm2.staticflickr.com/1536/25268890654_5310af6234_o.png&quot; width=&quot;1625&quot; height=&quot;1630&quot; alt=&quot;todolist2&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/zhaot777/angularjs_todolist.git&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;github code link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Go to www.addthis.com/dashboard to customize your tools --&gt;
&lt;div class=&quot;addthis_sharing_toolbox&quot;&gt;&lt;/div&gt;
</content>
    
    <summary type="html">
    
      This demo is a practice work for familiarizing Angular.js. The todo list can add new tasks, delete tasks and change the tasks condition from doing to done.
    
    </summary>
    
      <category term="Project" scheme="http://zhaot777.github.io/categories/Project/"/>
    
    
      <category term="Angular.js" scheme="http://zhaot777.github.io/tags/Angular-js/"/>
    
  </entry>
  
  <entry>
    <title>Web Crawler</title>
    <link href="http://zhaot777.github.io/2016/03/01/webcrawler/"/>
    <id>http://zhaot777.github.io/2016/03/01/webcrawler/</id>
    <published>2016-03-01T11:16:42.366Z</published>
    <updated>2016-03-03T08:51:12.588Z</updated>
    
    <content type="html">&lt;h3 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h3&gt;&lt;blockquote&gt;
&lt;font size=&quot;2&quot;&gt;&lt;p&gt;A &lt;strong&gt;Web crawler&lt;/strong&gt; starts with a list of URLs to visit, called the seeds. As the crawler visits these URLs, it identifies all the hyperlinks in the page and adds them to the list of URLs to visit, called the crawl frontier. URLs from the frontier are recursively visited according to a set of policies. If the crawler is performing archiving of websites it copies and saves the information as it goes. The archives are usually stored in such a way they can be viewed, read and navigated as they were on the live web, but are preserved as ‘snapshots’.- &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_crawler&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;wikipedia&lt;/a&gt;&lt;/p&gt;&lt;/font&gt;

&lt;/blockquote&gt;
&lt;p&gt;We can start from one seed page to search all the URLs with finite depth that we can get, then rank them in order, and give us the best choose or a rank list. And this is what the project does.&lt;br&gt;&lt;/p&gt;


&lt;h3 id=&quot;Project&quot;&gt;&lt;a href=&quot;#Project&quot; class=&quot;headerlink&quot; title=&quot;Project&quot;&gt;&lt;/a&gt;Project&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;For this project, Our goal is base on the keyword from input we return a list of URLs, that all of them contain the keyword and the most popular URL rank at the top.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt;We can divide the problem to several parts:&lt;/p&gt;
&lt;font size=&quot;2&quot;&gt;&lt;ol&gt;&lt;br&gt;&lt;li&gt;Get all the content from one page, we can use these content to find URLs and matched keyword&lt;/li&gt;&lt;br&gt;&lt;li&gt;Get all URLs from one page’s content&lt;/li&gt;&lt;br&gt;&lt;li&gt;Store all URLs that contain the keyword to a hash table from pages’ content&lt;/li&gt;&lt;br&gt;&lt;li&gt;Get a map of one page’s URL to all URLs that this page content, we can use this to rank our order&lt;/li&gt;&lt;br&gt;&lt;li&gt;Give as the rank list by using sorting algorithm&lt;/li&gt;&lt;br&gt;&lt;/ol&gt;&lt;/font&gt;


&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/zhaot777/PythonWebCrawler&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;github code link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Summary&quot;&gt;&lt;a href=&quot;#Summary&quot; class=&quot;headerlink&quot; title=&quot;Summary&quot;&gt;&lt;/a&gt;Summary&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt; This project is a just implement a simple function to get the URLs from a seed page.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt; It is base on the given input cache, which is a dictionary that stores all the URLs and maps content.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt;In fact, we can use Scrapy to help us to build a web crawler easier rather than write by ourselves.&lt;/p&gt;
&lt;h3 id=&quot;More-about-Web-Crawler&quot;&gt;&lt;a href=&quot;#More-about-Web-Crawler&quot; class=&quot;headerlink&quot; title=&quot;More about Web Crawler&quot;&gt;&lt;/a&gt;More about Web Crawler&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Scrapy is a free and open source web crawling framework written in Python. Originally designed for web scraping, it can also be used to extract data using APIs or as a general purpose web crawler.  &lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt; If there are large scare of output, we can use this tool crawling content and store in MongoDB.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt; Next time I will use Scrapy and MongoDB to implement the web crawler.&lt;/p&gt;
&lt;!-- Go to www.addthis.com/dashboard to customize your tools --&gt;
&lt;div class=&quot;addthis_sharing_toolbox&quot;&gt;&lt;/div&gt;
</content>
    
    <summary type="html">
    
      Web Crawler is a metasearch engine that blends the top search results. For this project, I wrote a web crawler by using Python, which can give us an order list of URLs of pages.
    
    </summary>
    
      <category term="Project" scheme="http://zhaot777.github.io/categories/Project/"/>
    
    
      <category term="Python" scheme="http://zhaot777.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Percolation Theory</title>
    <link href="http://zhaot777.github.io/2016/02/21/percolation/"/>
    <id>http://zhaot777.github.io/2016/02/21/percolation/</id>
    <published>2016-02-21T17:25:41.383Z</published>
    <updated>2016-03-03T08:51:01.711Z</updated>
    
    <content type="html">&lt;h3 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h3&gt;&lt;blockquote&gt;
&lt;font size=&quot;2&quot;&gt;In statistical physics and mathematics, percolation theory describes the behavior of connected clusters in a random graph. The applications of percolation theory to materials science and other domains are discussed in the article percolation. - &lt;a href=&quot;https://en.wikipedia.org/wiki/Percolation_theory&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;wikipedia&lt;/a&gt;&lt;/font&gt;

&lt;/blockquote&gt;
&lt;p&gt;Percolation model can be used in  many situations: It can represent how gas go through to the surface or how to find whether 2 people have connection in a social network. We can use union-find algorithm to build the connection.&lt;/p&gt;
&lt;h3 id=&quot;Union-Find&quot;&gt;&lt;a href=&quot;#Union-Find&quot; class=&quot;headerlink&quot; title=&quot;Union Find&quot;&gt;&lt;/a&gt;Union Find&lt;/h3&gt;&lt;blockquote&gt;
&lt;font size=&quot;2&quot;&gt;Union Find is an algorithm which uses a disjoint-set data structure to solve the following problem: Say we have some number of items. We are allowed to merge any two items to consider them equal (where equality here obeys all of the properties of an Equivalence Relation). At any point, we are allowed to ask whether two items are considered equal or not. - &lt;a href=&quot;http://www.algorithmist.com/index.php/Union_Find&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;algorithmist&lt;/a&gt;&lt;/font&gt;


&lt;/blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;font size=&quot;1&quot;&gt;  Algorithm &lt;/font&gt;&lt;/th&gt;
&lt;th&gt;&lt;font size=&quot;1&quot;&gt;  Time Complexity  &lt;/font&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;font size=&quot;1&quot;&gt; Quick find &lt;/font&gt;&lt;/td&gt;
&lt;td&gt;&lt;font size=&quot;1&quot;&gt;  M N &lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;font size=&quot;1&quot;&gt; Quick union &lt;/font&gt;&lt;/td&gt;
&lt;td&gt;&lt;font size=&quot;1&quot;&gt;M N &lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;font size=&quot;1&quot;&gt; weighted QU&lt;/font&gt;&lt;/td&gt;
&lt;td&gt;&lt;font size=&quot;1&quot;&gt;N + M log n &lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;font size=&quot;1&quot;&gt; weighted QU + path compression&lt;/font&gt;&lt;/td&gt;
&lt;td&gt;&lt;font size=&quot;1&quot;&gt; N + M lg* N &lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;font size=&quot;1&quot;&gt;&lt;strong&gt;*M union-find operations on a set of N objects&lt;/strong&gt;&lt;/font&gt;


&lt;h3 id=&quot;Project&quot;&gt;&lt;a href=&quot;#Project&quot; class=&quot;headerlink&quot; title=&quot;Project&quot;&gt;&lt;/a&gt;Project&lt;/h3&gt;&lt;p&gt;For this project, we use a N by N grid to represent the percolation model, at beginning all the sites of the grid is blocked, we randomly open the sites until we the system is be percolated.&lt;/p&gt;
&lt;p&gt;The goal of this project is to implement 2 class:&lt;br&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Percolation&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Percolation&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; N)&lt;/span&gt; &lt;span class=&quot;comment&quot;&gt;// create N-by-N grid, with all sites blocked&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i, &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; j)&lt;/span&gt; &lt;span class=&quot;comment&quot;&gt;// open site if it is not open already&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;isOpen&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i, &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; j)&lt;/span&gt;  &lt;span class=&quot;comment&quot;&gt;// is site (row i, column j) open?&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;isFull&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i, &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; j)&lt;/span&gt;  &lt;span class=&quot;comment&quot;&gt;// is site (row i, column j) full?&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;percolates&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;   &lt;span class=&quot;comment&quot;&gt;// does the system percolate?&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(String[] args)&lt;/span&gt;  &lt;span class=&quot;comment&quot;&gt;// test client (optional)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; class PercolationStats &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;PercolationStats&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; N, &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; T)&lt;/span&gt;  &lt;span class=&quot;comment&quot;&gt;// perform T independent experiments on an N-by-N grid&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;double&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;comment&quot;&gt;// sample mean of percolation threshold&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;double&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;comment&quot;&gt;// sample standard deviation of percolation threshold&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;double&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;confidenceLo&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;   &lt;span class=&quot;comment&quot;&gt;// low  endpoint of 95% confidence interval&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;double&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;confidenceHi&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;   &lt;span class=&quot;comment&quot;&gt;// high endpoint of 95% confidence interval&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(String[] args)&lt;/span&gt;  &lt;span class=&quot;comment&quot;&gt;// test client (described below)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;The first class is to simulate the percolation model, We need to open certain site and give sites’ condition.&lt;/p&gt;
&lt;p&gt;The second is to estimate the value of the percolation threshold via &lt;strong&gt;Monte Carlo simulation&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;font size=&quot;1&quot;&gt; &lt;strong&gt;Note:&lt;/strong&gt;&lt;br&gt; 1. The way to reduce time complexity  is to create 2 &lt;strong&gt;virtual nodes&lt;/strong&gt;, one is the top and one is the bottom.&lt;br&gt; 2. We need to consider how to avoid the backwash problem. The easy way to solve this problem is to use 2 union-find object to trace &lt;code&gt;all sites + 2 virtual nodes&lt;/code&gt; and &lt;code&gt;all sites + the top virtual node&lt;/code&gt;.&lt;/font&gt;

&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://coursera.cs.princeton.edu/algs4/assignments/percolation.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;project detail discription&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/zhaot777/algs4_Percolation.git&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;github code link&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Go to www.addthis.com/dashboard to customize your tools --&gt;
&lt;div class=&quot;addthis_sharing_toolbox&quot;&gt;&lt;/div&gt;
</content>
    
    <summary type="html">
    
      For this project, we use a N by N grid to represent the percolation model, at beginning all the sites of the grid is blocked, we randomly open the sites until we the system is be percolated.
    
    </summary>
    
      <category term="Project" scheme="http://zhaot777.github.io/categories/Project/"/>
    
    
      <category term="union-find" scheme="http://zhaot777.github.io/tags/union-find/"/>
    
  </entry>
  
</feed>
